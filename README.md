nachos
======

OS project
===========

project1
=======================================================================================================================
Task:
I. (5%, 5 lines) Implement KThread.join(). Note that another thread does not have to call join(), but if it is called, it must be called only once. The result of calling join() a second time on the same thread is undefined, even if the second caller is a different thread than the first caller. A thread must finish executing normally whether or not it is joined.
II. (5%, 20 lines) Implement condition variables directly, by using interrupt enable and disable to provide atomicity. We have provided a sample implementation that uses semaphores; your job is to provide an equivalent implementation without directly using semaphores (you may of course still use locks, even though they indirectly use semaphores). Once you are done, you will have two alternative implementations that provide the exact same functionality. Your second implementation of condition variables must reside in classnachos.threads.Condition2.
III. (10%, 40 lines) Complete the implementation of the Alarm class, by implementing the waitUntil(long x) method. A thread calls waitUntil to suspend its own execution until time has advanced to at least now + x. This is useful for threads that operate in real-time, for example, for blinking the cursor once per second. There is no requirement that threads start running immediately after waking up; just put them on the ready queue in the timer interrupt handler after they have waited for at least the right amount of time. Do not fork any additional threads to implement waitUntil(); you need only modify waitUntil() and the timer interrupt handler. waitUntil is not limited to one thread; any number of threads may call it and be suspended at any one time.
IV. (20%, 40 lines) Implement synchronous send and receive of one word messages (also known as Ada-style rendezvous), using condition variables (don't use semaphores!). Implement the Communicator class with operations, void speak(int word) and int listen().
speak()atomically waits untillisten()is called on the sameCommunicatorobject, and then transfers the word over tolisten(). Once the transfer is made, both can return. Similarly, listen() waits until speak() is called, at which point the transfer is made, and both can return (listen()returns the word). This means that neither thread may return from listen() or speak() until the word transfer has been made. Your solution should work even if there are multiple speakers and listeners for the same Communicator(note: this is equivalent to a zero-length bounded buffer; since the buffer has no room, the producer and consumer must
interact directly, requiring that they wait for one another). Each communicator should only use exactly one lock. If you're using more than one lock, you're making things too complicated.
V. (35%, 125 lines) Implement priority scheduling in Nachos by completing the PriorityScheduler class. Priority scheduling is a key building block in real-time systems. Note that in order to use your priority scheduler, you will need to change a line in nachos.conf that specifies the scheduler class to use. The ThreadedKernel.scheduler key is initially equal to nachos.threads.RoundRobinScheduler. You need to change this to nachos.threads.PriorityScheduler when you're ready to run Nachos with priority scheduling.
Note that all scheduler classes extend the abstract class nachos.threads.Scheduler. You must implement the methods getPriority(), getEffectivePriority(), and setPriority(). You may optionally also implementincreasePriority()anddecreasePriority()(these are not required). In choosing which thread to dequeue, the scheduler should always choose a thread of the highest effective priority. If multiple threads with the same highest priority are waiting, the scheduler should choose the one that has been waiting in the queue the longest.
An issue with priority scheduling is priority inversion. If a high priority thread needs to wait for a low priority thread (for instance, for a lock held by a low priority thread), and another high priority thread is on the ready list, then the high priority thread will never get the CPU because the low priority thread will not get any CPU time. A partial fix for this problem is to have the waiting thread donate its priority to the low priority thread while it is holding the lock.
Implement the priority scheduler so that it donates priority, where possible. Be sure to implement Scheduler.getEffectivePriority(), which returns the priority of a thread after taking into account all the donations it is receiving.
Note that while solving the priority donation problem, you will find a point where you can easily calculate the effective priority for a thread, but this calculation takes a long time. To receive full credit for the design aspect of this project, you need to speed this up by caching the effective priority and only recalculating a thread's effective priority when it is possible for it to change.
It is important that you do not break the abstraction barriers while doing this part -- the Lock class does not need to be modified. Priority donation should be accomplished by creating a subclass of ThreadQueue that will accomplish priority donation when used with the existing Lock class, and still work correctly when used with the existing Semaphore and Condition classes. Priority should also be donated through thread joins.
Priority Donation Implementation Details:
1) A thread's effective priority is calculated by taking the max of the donor's and the recipient's priority. If thread A with priority 4 donates to thread B with priority 2, then thread B's effective priority is now 4. Note that thread A's priority is also still 4. A thread that donates priority to another thread does not lose any of its own priority. For these reasons, the term "priority inheritance" is in many ways a more appropriate name than the term "priority donation".
2) Priority donation is transitive. If thread A donates to thread B and then thread B donates to thread C, thread B will be donating its new effective priority (which it received from thread A) to thread C.
VI. (25%, 150 lines) Now that you have all of these synchronization devices, use them to solve this problem. You will find condition variables to be the most useful synchronization method for this problem.
A number of Hawaiian adults and children are trying to get from Oahu to Molokai. Unfortunately, they have only one boat which can carry maximally two children or one adult (but not one child and one adult). The boat can be rowed back to Oahu, but it requires a pilot to do so.
Arrange a solution to transfer everyone from Oahu to Molokai. You may assume that there are at least two children.
The method Boat.begin() should fork off a thread for each child or adult. We will refer to the thread that called Boat.begin() as the parent thread. Your mechanism cannot rely on knowing how many children or adults are present beforehand, although you are free to attempt to determine this among the threads (i.e. you can't pass the parameters adults and children in the method begin() to your threads, but you are free to have each thread increment shared variables to try and determine this value, if you wish). To show that the trip is properly synchronized, make calls to the appropriate BoatGrader methods every time someone crosses the channel. When a child pilots the boat from Oahu to Molokai, call ChildRowToMolokai. When a child rides as a passenger from Oahu to Molokai, call ChildRideToMolokai. Make sure that when a boat with two people on it crosses, the pilot calls the ...RowTo... method before the passenger calls the ...RideTo... method.
Your solution must have no busy waiting, and it must eventually end. The simulation ends when the parent thread finishes running. Note that it is not necessary to terminate all the forked threads -- you can leave them blocked waiting for a condition variable. While you cannot pass the number of threads created to the threads representing adults and children, you can and probably will need to use this number in begin() in order to determine when all the adults and children are across and you can return.
The idea behind this task is to use independent threads to solve a problem. You are to program the logic that a child or an adult would follow if that person were in this situation. For example, it is reasonable to allow a person to see how many children or adults are on the same island they are on. A person could see whether the boat is at their island. A person can know which island they are on. All of this information may be stored with each individual thread or in shared variables. So a counter that holds the number of children on Oahu would be allowed, so long as only threads that represent people on Oahu could access it.
What is not allowed is a thread which executes a "top-down" strategy for the simulation. For example, you may not create threads for children and adults, then have a controller thread simply send commands to them through communicators. The threads must act as if they were individuals. Information which is not possible in the real world is also not allowed. For example, a child on Molokai cannot magically see all of the people on Oahu. That child may remember the number of people that he or she has seen leaving, but the child may not view people on Oahu as if it were there. (Assume that the people do not have any technology other than a boat!)
You will reach a point in your simulation where the adult and child threads believe that everyone is across on Molokai. At this point, you are allowed to do one-way communication from the adult/child threads to begin() (the parent thread) in order to inform it that the simulation may be over. It may be possible, however, that your adult and child threads are incorrect. Your simulation must handle this case without requiring explict or implict communication from begin() (the parent thread) to the adult/child threads.
=======================================================================================================================


project2
=======================================================================================================================
Task:
I.(30%, 125 lines) Implement the file system calls (creat, open, read, write, close, and unlink, documented in syscall.h). You will see the code for halt in UserProcess.java; it is best for you to place your new system calls here too. Note that you are not implementing a file system; rather, you are simply giving user processes the ability to access a file system that we have implemented for you.
 We have provided you the assembly code necessary to invoke system calls from user programs (seestart.s; theSYSCALLSTUBmacro generates assembly code for each syscall).
 You will need to bullet-proof the Nachos kernel from user program errors; there should be nothing a user program can do to crash the operating system (with the exception of explicitly invoking the halt() syscall). In other words, you must be sure that user programs do not pass bogus arguments to the kernel which causes the kernel to corrupt its internal state or that of other processes. Also, you must take steps to ensure that if a user process does anything illegal -- causing the Processor to throw an exception -- that the process will be killed cleanly and its resources freed.
 You should make it so that the halt() system call can only be invoked by the "root" process -- that is, the first process in the system. If another process attempts to invoke halt(), the system call should be ignored and return immediately.
 Since the memory addresses passed as arguments to the system calls are virtual addresses, you need to use UserProcess.readVirtualMemory and UserProcess.writeVirtualMemory to transfer memory between the user process and the kernel.
 User processes store filenames and other string arguments as null-terminated strings in their virtual address space. The maximum length of for strings passed as arguments to system calls is 256 bytes (not including the terminating null).
 When a system call wishes to indicate an error condition to the user, it should return -1 (not throw an exception within the kernel!). Otherwise, the system call should return the appropriate value as documented in test/syscall.h.
 When any process is started, its file descriptors 0 and 1 must refer to standard input and standard output. Use UserKernel.console.openForReading() and UserKernel.console.openForWriting() to make this easier. A user process is allowed to close these descriptors, just like descriptors returned by open(). Do not worry about reopening them if they are closed.
 A stub file system interface to the UNIX file system is already provided for you; the interface is given by the classmachine/FileSystem.java. You can access the stub filesystem through the static fieldThreadedKernel.fileSystem. (Note that since UserKernelextends ThreadedKernel, you can still access this field.) This filesystem is capable of accessing the test directory in your Nachos distribution, which is going to be useful when you want to support the exec system call (see below). You do not need to implement any file system functionality. You should examine carefully the specifications for FileSystem and StubFileSystem in order to determine what functionality you should provide in your syscalls, and what is handled by the file system.
 Do not implement any kind of file locking; this is the file system's responsibility. If ThreadedKernel.fileSystem.open() returns a non-null OpenFile, then the user process is allowed to access the given file; otherwise, you should signal an error. Likewise, you do not need to worry about the details of what happens if multiple processes attempt to access the same file at once; the stub filesystem handles these details for you.

II.

Your implementation should support up to 16 concurrently open files per process, including stdin and stdout. Each file that a process has opened should have a uniquefile descriptor associated with it (see syscall.h for details). The file descriptor should be a non- negative integer that is simply used to index into a table of currently-open files by that process. Note that a given file descriptor can be reused if the file associated with it is closed, and that different processes can use the same file descriptor (i.e. integer) to refer to different files.
(25%, 100 lines) Implement support for multiprogramming. The code we have given you is restricted to running one user process at a time; your job is to make it work for multiple user processes.
Come up with a way of allocating the machine's physical memory so that different processes do not overlap in their memory usage. Note that the user programs do not make use of malloc() or free(), meaning that user programs effectively have no dynamic memory allocation needs (and therefore, no heap). What this means is that you know the complete memory needs of a process when it is created. You can allocate a fixed number of pages for the processe's stack; 8 pages should be sufficient.
We suggest maintaining a global linked list of free physical pages (perhaps as part of the UserKernel class). Be sure to use synchronization where necessary when accessing this list. Your solution must make efficient use of memory by allocating pages for the new process wherever possible. This means that it is not acceptable to only allocate pages in a contiguous block; your solution must be able to make use of "gaps" in the free memory pool.
Also be sure that all of a process's memory is freed on exit (whether it exits normally, via the syscall exit(), or abnormally, due to an illegal operation).
Modify UserProcess.readVirtualMemory and UserProcess.writeVirtualMemory, which copy data between the kernel and the user's virtual address space, so that they work with multiple user processes.
The physical memory of the MIPS machine is accessed through the methodMachine.processor().getMemory(); the total number of physical pages is Machine.processor().getNumPhysPages(). You should maintain the pageTable for each user process, which maps the user's virtual addresses to physical addresses. The TranslationEntry class represents a single virtual-to-physical page translation.
The field TranslationEntry.readOnly should be set to true if the page is coming from a COFF section which is marked as read-only. You can determine this using the method CoffSection.isReadOnly().
Note that these methods should not throw exceptions when they fail; instead, they must always return the number of bytes transferred (even if that number is zero).
Modify UserProcess.loadSections() so that it allocates the number of pages that it needs (that is, based on the size of the user program), using the allocation policy that you decided upon above. This method should also set up the pageTable structure for the process so that the process is loaded into the correct physical memory pages. If the new user process cannot fit into physical memory, exec() should return an error.


IV.
III.
Note that the user threads (see the UThread class) already save and restore user machine state, as well as process state, on context switches. So, you are not responsible for these details.
(30%, 125 lines) Implement the system calls (exec, join, and exit, also documented
in syscall.h).
 Again, all the addresses passed in registers to exec and join are virtual addresses. You
should use readVirtualMemory and readVirtualMemoryString to transfer memory between
the kernel and the user process.
 Again, you must bullet-proof these syscalls.
 Note that the state of the child process is entirely private to this process. This means that
the parent and child do not directly share memory or file descriptors. Note that two processes can of course open the same file; for example, all processes should have file descriptors 0 and 1 mapped to the system console, as described above.
 Unlike KThread.join(), only a process's parent can join to it. For instance, if A executes B and B executes C, A is not allowed to join to C, but B is allowed to join to C.
 join takes a process ID as an argument, used to uniquely identify the child process which the parent wishes to join with. The process ID should be a globally unique positive integer, assigned to each process when it is created. (Although for this project the only use of the process ID is in join, for later project phases it is important that the process ID is unique across all running processes in the system.) The easiest way of accomplishing this is to maintain a static counter which indicates the next process ID to assign. Since the process ID is an int, then it may be possible for this value to overflow if there are many processes in the system. For this project you are not expected to deal with this case; that is, assume that the process ID counter will not overflow.
 When a process calls exit(), its thread should be terminated immediately, and the process should clean up any state associated with it (i.e. free up memory, close open files, etc). Perform the same cleanup if a process exits abnormally.
 The exit status of the exiting process should be transferred to the parent, in case the parent calls the join system call. The exit status of a process that exits abnormally is up to you. For the purposes of join, a child process exits normally if it calls the exit syscall with any status, and abnormally if the kernel kills it (e.g. due to an unhandled exception).
 The last process to call exit() should cause the machine to halt by calling Kernel.kernel.terminate(). (Note that only the root process should be allowed to
invoke the halt() system call, but the last exiting process should call Kernel.kernel.terminate() directly.)
(15%, 50 lines+existing priority scheduler) Implement a lottery scheduler (place it in threads/LotteryScheduler.java). Note that this class extends PriorityScheduler, you should be able to reuse most of the functionality of that class; the lottery scheduler should not be a large amount of additional code. The only major difference is the mechanism used to pick a thread from a queue: a lottery is held, instead of just picking the thread with the most priority. Your lottery scheduler should implement priority donation. (Note that since this is a lottery scheduler, priority inversion can't actually lead to starvation! However, your scheduler must do priority donation anyway.)
 In a lottery scheduler, instead of donating priority, waiting threadstransfer ticketsto threads they wait for. Unlike a standard priority scheduler, a waiting thread always adds its ticket count to the ticket count of the queue owner; that is, the owner's ticket count is the sumof its own tickets and the tickets of all waiters, not the max. Be sure to implement this correctly.
 Your solution should work even if there are billions of tickets in the system (i.e. do not keep an array containing an entry for every ticket).
 When LotteryScheduler.increasePriority() is called, the number of tickets held by a process should be incremented by one. Similarly, for decreasePriority(), the number should be decremented by one.
 The total number of (real) tickets in the system is guaranteed not to exceed Integer.MAX_VALUE. The maximum individual priority is now also Integer.MAX_VALUE, rather than 7 (PriorityScheduler.priorityMaximum). If you wish, you may also assume that the minimum priority is increased to 1 (from 0).
=======================================================================================================================


proj3
=======================================================================================================================
Task:
I.
(30%) Implement software-management of the TLB, with software translation via an inverted page table.
 Since VMProcess extends UserProcess, you should not have to duplicate much code fromUserProcess; that is, only override what's necessary and call methods in the superclass for everything else.
 The way to handle TLB misses is to add code to VMProcess.handleException which deals with theProcessor.exceptionTLBMiss exception. The virtual address causing the TLB miss is obtained by calling Machine.processor().readRegister(Processor.regBadVaddr).
 Some methods you will need to use are: Machine.processor().getTLBSize() (obtains the size of the processor's TLB), Machine.processor().readTLBEntry() (reads a TLB entry), andMachine.processor().writeTLBEntry() (writes a TLB entry). Note that TLB entries are of typeTranslationEntry, the same class used for page table entries in project phase 2.
 When you run Nachos from the proj3 directory, the processor no longer deals with page tables (as it did in phase 2); instead, the processor traps to the OS on a TLB miss. This provides the flexibility to implement inverted page tables without changing anything about the processor simulation.
II.
 You will need to do make sure that TLB state is set up properly on a context switch. Most systems simply invalidate all the TLB entries on a context switch, causing entries to be reloaded as the pages are referenced.
 Your TLB replacement policy can be random, if you wish. The only requirement is that your policy makes use of all TLB entries (that is, don't simply use a single TLB entry or something weird like that).
 You should use a single global inverted page table for all processes. (This is a departure from the use of per-process page tables from phase 2.) Because the inverted page table is global, each key used to look up an entry in the table will need to contain both the current process ID and the virtual page number. You may use the standard Java java.util.Hashtable class to implement the inverted page table, but do not depend upon the fact that this class is synchronized to avoid changes being made to it by multiple threads.
 Only invalidate TLB entries when it is necessary to do so (e.g. on context switches).
 Don't forget to set used and dirty bits where necessary
in readVirtualMemory andwriteVirtualMemory.
(40%) Implement demand paging of virtual memory. For this, you will need routines to move a page from disk to memory and from memory to disk. You should use the Nachos stub file system as backing store; this will make Part 3 (see below) a lot easier.
 In order to find unreferenced pages to throw out on page faults, you will need to keep track of all of the pages in the system which are currently in use. You should consider using a core map, an array that maps physical page numbers to the virtual pages that are stored there.
 The inverted page table must only contain entries for pages that are actually in physical memory. You will need to maintain a separate data structure for locating pages in swap.
 The Nachos TLB sets the dirty and used bits, which you can use to implement the clock algorithm for page replacement. Alternately, you may choose to implement the nth chance clock algorithm as described in the lecture notes (see the textbook for more details on these algorithms).
 Your page-replacement policy should not write any pages to the swap file which have not been modified (i.e. for which the dirty bit is not set). Thus, you will be required to keep pages around in swap even if they have been moved to physical memory.
 Now that pages are being moved to and from memory and disk, you need to ensure that one process won't try to move a page while another process is performing some other operation on it (e.g., areadVirtualMemory or writeVirtualMemory operation, or loading the contents of the page from a disk file). You should not use a separate Lock for every page -- this is highly inefficient.
 We recommend that you use a single global swap file shared by all processes. You may use any format you wish for this file, but it should be rather simple as long as you keep track of where different virtual pages are stored in the file. You may assume that it's safe to grow the swap file to an arbitrary size; that is, you don't need to be concerned about running out of disk space for this file. (If a read or write operation on the swap file returns fewer bytes than requested, this is a fatal error.) To conserve disk space, you should reuse unallocated swap file space; a simple list of free swap file pages is sufficient for this.
 The swap file should be closed and deleted when VMKernel.terminate() is called.
 If a process experiences an I/O error when accessing the swap file, you should kill the
process.
 You should test the performance of your page-replacement algorithm by comparing it to a
simpler algorithm, such as random replacement. A good way to test this is to write a MIPS C program which does a lot of paging; test/matmult.c is a good example. By counting the
III.
number of page faults, you can compare the performance of your algorithm with random replacement. We will grade your algorithm in part based on the page fault rate as compared to a simple replacement policy.
 Note that it is possible to experience indefinite thrashing when the system has only a single physical page of memory if a process attempts to perform a load/store operation (convince yourself why!). Your implementation need not deal with this case.
(30%) Implement lazy loading of the code and data pages from user programs. That is, rather than reading all of the code and data from a user program at startup time, set up page table entries so that when page faults occur, the pages from the executable will be read into memory on demand.
 You must ensure that changes to the memory image of the executable are not written back to the executable file. Code pages are always read-only, so there is no danger that the user process can modify them during execution. However, the data pages from the executable (representing global variables and the like) may be modified by the process. Ensure that these changes are not written back to the executable file.
 In addition to lazy-loading pages from the executable file, you should allocate stack pages on demand as well. So, you should not allocate the full set of stack pages to the process when it is initialized; rather, when a page fault occurs on a stack page, you should allocate a new stack page at that time. Think carefully about how stack pages should be allocated and initialized, and in particular, about the security issues involved.
 As with project phase 2, the maximum number of stack pages needed by a process is 8.
Be aware that in project 3 you may run into live-lock. This is a case where your user programs will appear to have deadlocked - they will not be able to make any forward progress. There is a possibility that this will happen if you are running more than one user program with a small number of physical pages. You are not required to fix this problem. The autograder will not run any sequence that could possibly result in live-lock.
If you run more than 1 process, you risk live-lock for the case when two processes running can both get _double_ TLB misses (one for the instruction and one for data). This can result in live-lock depending on the luck of context switching and everything.
Here is an example (with two processes running, #1 & #2): #1 TLB miss on instruction & data
#1 Acquire lock to service data
CONTEXT SWITCH
#2 TLB miss on instruction & data
#2 Go to sleep waiting for lock to service data
CONTEXT SWITCH
#1 Finish service on data
#1 Release lock, giving it to #2 since it is on the queue
#1 Try to acquire the lock for instruction
#1 Go to sleep because #2 has the lock
CONTEXT SWITCH
#2 Invalidate TLB because of context switch, removing the service #1 has done on data #2 Service it's own data
#2 Release lock, giving it to #1 since it is on the queue
#2 Try to acquire lock for instruction
#2 Go to sleep because #1 has the lock
CONTEXT SWITCH
#1 Invalidate TLB because of context switch, removing the service #2 has done on data #1 Service instruction miss
#1 Release lock, giving it to #2 since it is on the queue
#1 Try to acquire lock because we need to re-service data
#1 Go to sleep because #2 has the lock CONTEXT SWITCH
...
In order to fix this, you would have to guarantee that at least one process is guaranteed to have 2 TLB translations as well as those 2 corresponding pages in memory before being context switched. This way, at least one process would be able to make progress on a double-miss instruction. You could lessen the effects of live-lock by saving and restoring the state of the TLB on context switches, but the same problem can occur with very few pages of physical memory. In this case, 2 processes could get stuck in a similar way by continually throwing out each others pages before both the instruction and data page could be loaded.
Also be careful that you don't write off other bugs in your project as live-lock. Live-lock is fairy rare and non-deterministic to get. It will only occur when running multiple user programs. I recommend lots of black/white box and stub file testing before you do full integration testing by running user programs.
=======================================================================================================================
